<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tech on Dery R Ahaddienata</title><link>https://deryrahman.github.io/tags/tech/</link><description>Recent content in tech on Dery R Ahaddienata</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 19 Jul 2021 15:49:33 +0700</lastBuildDate><atom:link href="https://deryrahman.github.io/tags/tech/index.xml" rel="self" type="application/rss+xml"/><item><title>Software System Fundamentals</title><link>https://deryrahman.github.io/posts/software-system-fundamentals/</link><pubDate>Mon, 19 Jul 2021 15:49:33 +0700</pubDate><guid>https://deryrahman.github.io/posts/software-system-fundamentals/</guid><description>The book I&amp;rsquo;m currently reading is Designing Data Intensive Applications by Martin Kleppmann. During the first read, I found concise fundamentals we need to concern most when dealing with a high quality software system. There&amp;rsquo;re 3 fundamentals as follow:
Fundamental Definition Reliability The system should work properly even when the things go wrong (faulty) Scalability The system should be able to handle the growth (data volume, traffic, or complexity) Maintainability The system should easily adaptable enough during maintenance (bugs, failures, and new features) Reliability Faulty can come up from several places:</description><content>&lt;p>The book I&amp;rsquo;m currently reading is &lt;a href="https://learning.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/">Designing Data Intensive Applications&lt;/a> by Martin Kleppmann. During the first read, I found concise fundamentals we need to concern most when dealing with a high quality software system. There&amp;rsquo;re 3 fundamentals as follow:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Fundamental&lt;/th>
&lt;th>Definition&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Reliability&lt;/strong>&lt;/td>
&lt;td>The system should work properly even when the things go wrong (faulty)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Scalability&lt;/strong>&lt;/td>
&lt;td>The system should be able to handle the growth (data volume, traffic, or complexity)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Maintainability&lt;/strong>&lt;/td>
&lt;td>The system should easily adaptable enough during maintenance (bugs, failures, and new features)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="reliability">Reliability&lt;/h2>
&lt;p>Faulty can come up from several places:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Hardware Faults&lt;/strong>: eg. Hard disk has MTTF (mean time to failure) of about 10 to 50 years.&lt;/li>
&lt;li>&lt;strong>Software Faults&lt;/strong>: eg. Uncaught bugs in Linux kernel due to leap second on June 20, 2012.&lt;/li>
&lt;li>&lt;strong>Human Errors&lt;/strong>: eg. Configuration error by operators leads the most system outage.&lt;/li>
&lt;/ul>
&lt;h2 id="scalability">Scalability&lt;/h2>
&lt;p>Data growth is equal to increasing load. There&amp;rsquo;re 2 things need to describe:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Load&lt;/strong>: current load existing on the system. Some parameters:
&lt;ul>
&lt;li>request per second&lt;/li>
&lt;li>response time&lt;/li>
&lt;li>read write ration on DB&lt;/li>
&lt;li>number of concurrent user&lt;/li>
&lt;li>hit rate on cache&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Performance&lt;/strong>: metrics that used to define how good the system handle load. It can be used as SLA / SLO. Some metrics:
&lt;ul>
&lt;li>avg / mean&lt;/li>
&lt;li>median: p50&lt;/li>
&lt;li>percentile: p95, p99, p999&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="maintainability">Maintainability&lt;/h2>
&lt;p>The goal is to minimize pain during maintenance. Three design principles need to follow:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Operability&lt;/strong>: make it easy for teams to keep the system run smoothly.&lt;/li>
&lt;li>&lt;strong>Simplicity&lt;/strong>: make it easy for new engineer to understand the system.&lt;/li>
&lt;li>&lt;strong>Evolvability&lt;/strong>: make it easy for engineer to extend the system.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>References&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://learning.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/">Designing Data Intensive Applications&lt;/a> by Martin Kleppmann&lt;/li>
&lt;/ol></content></item><item><title>Redis Cluster Migration Strategy</title><link>https://deryrahman.github.io/posts/redis-cluster-migration-strategy/</link><pubDate>Sat, 17 Jul 2021 23:16:48 +0700</pubDate><guid>https://deryrahman.github.io/posts/redis-cluster-migration-strategy/</guid><description>Last week I have a chance to perform Redis cluster migration. Our Redis cluster contains 6 high memory VMs. At peak, it has 800 request/second. In this article I would like to explain how we migrate Redis cluster with zero downtime as well as lesson learned I&amp;rsquo;ve gathered.
Problem Statement As Ubuntu 16.04 no longer support LTS, we need to upgrade some obsolete VMs to latest version (20.04). One of the obsolete VMs are our Redis cluster.</description><content>&lt;p>Last week I have a chance to perform Redis cluster migration. Our Redis cluster contains 6 high memory VMs. At peak, it has 800 request/second. In this article I would like to explain how we migrate Redis cluster with zero downtime as well as lesson learned I&amp;rsquo;ve gathered.&lt;/p>
&lt;h2 id="problem-statement">Problem Statement&lt;/h2>
&lt;p>As Ubuntu 16.04 no longer support LTS, we need to upgrade some obsolete VMs to latest version (20.04). One of the obsolete VMs are our Redis cluster. Most of the services rely on our service that use this Redis cluster as in-memory storage. Upgrading the OS inside the node is not the option since it require complex reconfiguration as well as inevitable downtime.&lt;/p>
&lt;p>We&amp;rsquo;re using Redis version 5.0.9, with GCP VM n2-highmem-4. The cluster contains 3 master nodes and 3 slave nodes. The keys are stored in memory that filled up 16GB across 3 partitions.&lt;/p>
&lt;h2 id="goal">Goal&lt;/h2>
&lt;p>Upgrade the Ubuntu version (16.04) of all Redis cluster nodes to 20.14 with zero downtime.&lt;/p>
&lt;h2 id="approach">Approach&lt;/h2>
&lt;p>First we spin up new GCP VM with Ubuntu 20.04 installed. Then install and configure the Redis so that this new Redis are ready to join to the existing cluster. Then add this node to the cluster as a slave of partition 1. Wait for this slave to sync the data with the master. Repeat it for the partition 2 and 3. Then perform manual failover so the new node will be promoted as a new master. Finally, detach all the old Redis nodes from cluster. It seems like quite easy. Yes it does. But in practice, we have a challenge. The challenge will be explained in the &lt;a href="#lesson-learned">Lesson Learned&lt;/a> section.&lt;/p>
&lt;p>Put image here (TBD)&lt;/p>
&lt;p>Here&amp;rsquo;re some steps in details:&lt;/p>
&lt;ol>
&lt;li>Spin up new GCP VM. I won&amp;rsquo;t explain how to do that since it&amp;rsquo;s out of scope from our topic.&lt;/li>
&lt;li>Configure Redis 5.0.9 to meet minimum requirement as a node cluster. All configuration can be seen &lt;a href="https://redis.io/topics/cluster-tutorial">here&lt;/a>.
&lt;div class="collapsable-code">
&lt;input id="1" type="checkbox" />
&lt;label for="1">
&lt;span class="collapsable-code__language">conf&lt;/span>
&lt;span class="collapsable-code__title">redis.conf&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="△" data-label-collapse="▽">&lt;/span>
&lt;/label>
&lt;pre class="language-conf" >&lt;code>
cluster-node-timeout 100
cluster-enabled yes
cluster-config-file &amp;#34;auto-nodes.conf&amp;#34;
cluster-replica-validity-factor 1
cluster-require-full-coverage no
aof-use-rdb-preamble yes
&lt;/code>&lt;/pre>
&lt;/div>
&lt;/li>
&lt;li>Add the new node to the existing cluster as a slave. Wait for this new node to perform full sync with master. We have 3 node partitions, make sure this new node will join as a slave of corresponding master.
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">redis-cli --cluster add-node &amp;lt;new_redis_box_ip&amp;gt;:6379 &amp;lt;any_old_redis_box_ip&amp;gt;:6379 --cluster-slave --cluster-master-id &amp;lt;master_id&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Repeat step 1-3 for each partitions. The result, there&amp;rsquo;re 2 new slaves for each partition. Total nodes in cluster is 12, 6 old nodes, other 6 are new nodes.&lt;/li>
&lt;li>&lt;a href="https://redis.io/commands/cluster-failover">Failover&lt;/a> the old master and promote new node as a master for each partitions.
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">redis-cli -h &amp;lt;new_redis_box_ip&amp;gt; -p &lt;span style="color:#ae81ff">6379&lt;/span>
&lt;span style="color:#75715e"># run redis-cli command: CLUSTER FAILOVER&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Detach 6 old nodes from the cluster.
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">redis-cli --cluster del-node &amp;lt;new_redis_box_ip&amp;gt;:6379 &amp;lt;old_node_id&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h2 id="lesson-learned">Lesson Learned&lt;/h2>
&lt;p>When we do step 3, there&amp;rsquo;s a huge missing read request. After we seek for the root cause it happens because during full sync, ~5GB data transfer from master to new slave, the new slave will fill up the huge data to memory from disk. This activity leads to high CPU usage on our new slave node. Thus, some request that read data from this slave would not be proceeded.&lt;/p>
&lt;p>Before that, we also suspect it&amp;rsquo;s because of the fork process during RDB backup on the master. Redis cluster use RDB file to sync with the replica. And yup, fork process on Redis would consume huge CPU. But if this is the cause, it could be the issue for a long time ago, since the sync process between master and slave is always happening.&lt;/p>
&lt;p>Second suspect is &lt;a href="https://github.com/redis/redis/issues/4815">due to bandwidth limit&lt;/a>. During full sync process, master and slave will transfer the data as fast as possible so that the bandwidth is reach its limit. Hence, it will cause the request blocking. But, after we saw from our monitoring tool, we didn&amp;rsquo;t see any request error when master was transfering data to the new slave.&lt;/p>
&lt;p>The request was blocked when new slave fill up the new data. It happened so fast so that the CPU usage was 100%. Some requests that read from this new slave was failing. We still didn&amp;rsquo;t know and the inner process how the Redis fill up memory from zero. We also seek for a solution to hold the Redis read from specific slave, but we didn&amp;rsquo;t see any configuration to configure this. The close possible solution is &lt;code>cluster-allow-reads-when-down&lt;/code>, but it&amp;rsquo;s for redis 6.0. We didn&amp;rsquo;t have time to explore this deeper.&lt;/p>
&lt;p>Thus we planned to do this migration during off hour.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>We&amp;rsquo;re fail to do Redis cluster migration with zero downtime. But, we know for sure that this strategy is worked when data it not big. We performed the Redis cluster migration on integration, and we achieved zero error and zero downtime. Perhaps, if we can block the Redis read on the new slave, it might probably help when the new slave perform a full sync from master node.&lt;/p>
&lt;p>&lt;strong>References&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://redis.io/topics/cluster-tutorial">https://redis.io/topics/cluster-tutorial&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://redis.io/commands/cluster-failover">https://redis.io/commands/cluster-failover&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/redis/redis/issues/4815">https://github.com/redis/redis/issues/4815&lt;/a>&lt;/li>
&lt;/ol></content></item><item><title>Slow Coding</title><link>https://deryrahman.github.io/posts/slow-coding/</link><pubDate>Fri, 09 Apr 2021 18:27:48 +0700</pubDate><guid>https://deryrahman.github.io/posts/slow-coding/</guid><description>I wrote this article for my own documentation related to lesson learned I was gathered during my coding-life. Really, up until now, coding is fun. The way we transfer our idea and logic into code so that computer can do whatever we want seems really magical. There&amp;rsquo;s a joke I&amp;rsquo;ve found somewhere (I forget exactly), today&amp;rsquo;s magician is programmer. It&amp;rsquo;s quite true, imagine the world which can do so much things, efficiently, automatically, and precisely without human inference.</description><content>&lt;p>I wrote this article for my own documentation related to lesson learned I was gathered during my coding-life. Really, up until now, coding is fun. The way we transfer our idea and logic into code so that computer can do whatever we want seems really magical. There&amp;rsquo;s a joke I&amp;rsquo;ve found somewhere (I forget exactly), today&amp;rsquo;s magician is programmer. It&amp;rsquo;s quite true, imagine the world which can do so much things, efficiently, automatically, and precisely without human inference. It can be done with computer.&lt;/p>
&lt;p>But the ugliest fact is that thing is dumb, computer can&amp;rsquo;t do anything meaningful unless someone instructs the machine to do something. How to instruct the computer? Through code. Code is just an alternate name of computer instruction which computer can understand. To code, or we can say coding, is quite similar with typing. The fun part, coding/typing is like a playing keyboard, it satisfies if we could type it fast. Expecially when you use mechanical keyboard :)&lt;/p>
&lt;hr>
&lt;p>On typing, we use natural language, we know english, indonesian, japanese, etc. On coding, we use programming language, we know golang, python, ruby, etc. To type/code we need to understand the language syntax, grammar, and meaning. Both translates conceptual abstraction into text. On typing, if we don&amp;rsquo;t know the concept idea / the topic / story, we can&amp;rsquo;t write the article, even we know fluently about the grammar and the words meaning. Same with coding, we&amp;rsquo;ll stuck and don&amp;rsquo;t know what to code if we didn&amp;rsquo;t know the bigger picture of the abstract system we want to build. It can tremendously slow down the coding process. To understand the bigger picture is to understand how to code effectively. I&amp;rsquo;ve ever experienced to not knowing bigger picture of the flow of the service our team owned, so I code blindly without knowing the side effect of my code.&lt;/p>
&lt;blockquote>
&lt;p>To understand the bigger picture is to understand how to code effectively&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>Another thing which is important to know it our dev environment. I used to be frequently use mouse on coding process. At the first time, it won&amp;rsquo;t bother me, up until I felt it&amp;rsquo;s so slow to move my hand from keyboard to trackpad / mousepad. So iteratively I built the dev environment (which still ongoing and continually improved forever) to support coding speed ability. In my current company, I usually use golang and ruby. I experimented with several IDE shortcuts to match with my finger, but nothing satisfies me. The keyboard shortcut is differ from IDE to another. And IDE can mostly slow down your computer. Hence I move to Vim. Really I like it. Now I&amp;rsquo;m the big fans of any terminal related tools. So, if anything can be done in terminal, I prefer to use it. It&amp;rsquo;s hard at the first time, but, eventually your finger can adapt, and it can speed up the process. The brain and the finger are merged. Later I will create my dev environment setup with minimal switching so everything can be done with keyboard.&lt;/p>
&lt;blockquote>
&lt;p>Tweak the dev environment to reduce keyboard-mouse switching time. And mastering the shortcut&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>We mostly spend our time in front of computer. So any ergonomic desk configuration needs to addressed. There&amp;rsquo;s a &lt;a href="https://www.youtube.com/watch?v=">youtube channel I recently watch related to ergonomic desk setup&lt;/a>. I personally create the room environment as minimalist as possible yet can support my body keep in normal position so any stressed can be reduced. Ergonomic is the key, I&amp;rsquo;ve ever use a chair which are not comfortable enough. The result, I can only spend a little amount of my productivity time. And never want to in front of computer screen again. Besides that, the exercise is also important. I personally trained myself discipline to take a 10 minutes yoga stretch in the morning, do abs sit up, and do 3 set of push up. In my free time, I also workout in gym. What we eat is also important to keep our brain keep active. Hence it can improve our understanding of the coding process. Finally it can improve the coding speed. I will create another article related to my desk minimalist setup, workout tips, and food meal I&amp;rsquo;ve prepared every day. We need to keep our body + brain healthy in order to boost the productivity.&lt;/p>
&lt;blockquote>
&lt;p>We need to keep our body + brain healthy in order to boost the productivity&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>That&amp;rsquo;s it. Now I&amp;rsquo;m going to continue read kindle, Sapiens: A Brief History of Humankind, by Yuval Noah Harari :). Happy coding, keep learning, stay humble, and eventually you will be able to bring a larger impact on society through code.&lt;/p></content></item></channel></rss>