<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubernetes on Dery R Ahaddienata</title><link>https://dery.dev/tags/kubernetes/</link><description>Recent content in kubernetes on Dery R Ahaddienata</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 19 Feb 2025 23:41:09 +0700</lastBuildDate><atom:link href="https://dery.dev/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Kubernetes Connectivity Unreachable?</title><link>https://dery.dev/posts/2025-02-k8s-connectivity-unreachable/</link><pubDate>Wed, 19 Feb 2025 23:41:09 +0700</pubDate><guid>https://dery.dev/posts/2025-02-k8s-connectivity-unreachable/</guid><description>Recently, I tried to setup the k8s cluster in my local. Unlike many common setup out there where we usually use minikube, kindD, or k3s, this time I play using vm directly. This exercise allow me to have a better understanding on how k8s manages the containers.
I use lima vm to create a vm in my mac. Previously I have several candidates, like VirtualBox and VMWare, but it&amp;rsquo;s quite heave and more resource consuming.</description><content>&lt;p>Recently, I tried to setup the k8s cluster in my local. Unlike many common setup out there where we usually use minikube, kindD, or k3s, this time I play using vm directly. This exercise allow me to have a better understanding on how k8s manages the containers.&lt;/p>
&lt;p>I use lima vm to create a vm in my mac. Previously I have several candidates, like VirtualBox and VMWare, but it&amp;rsquo;s quite heave and more resource consuming. Yet, I found lima vm as an alternative that I feel like it&amp;rsquo;s more lightweight. I tried to spin up 2 VMs, one for control-plane and other for worker. I use user-v2 and vzNAT as a network. Former for vm to vm communication and latter for vm to host communication (yes, I need this for exposing LoadBalancer service, because I want to mess this things up ðŸ™‚). So, with this setup, 1 node has 2 network interface. Then, this is where connectivity issue araises..&lt;/p>
&lt;hr>
&lt;h1 id="kube-proxy-crashed-on-worker-node">kube-proxy crashed on worker node&lt;/h1>
&lt;p>When adding a worker node with 2 interfaces, kube-proxy always crash due to the hostname &lt;code>lima-vm-control-plane.internal&lt;/code> can&amp;rsquo;t resolved. So we need to debug, why it&amp;rsquo;s not resolved:&lt;/p>
&lt;ul>
&lt;li>Most likely the problem lies on dns resolution. Turns out when I run debug container on worker node and try to &lt;code>nslookup&lt;/code> that hostname, it&amp;rsquo;s not resolved&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Root cause:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>In that container, &lt;code>/etc/resolv.conf&lt;/code> is wrongly ordered:
&lt;pre>&lt;code>nameserver 192.168.106.1
nameserver fe80::184a:53ff:fe41:e165%3
nameserver 192.168.104.2
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>It first lookup on 192.168.106.1 which is vzNAT and it&amp;rsquo;s not accessible through worker&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>First, we should find, how resolv.conf is assined to the container. Turns out it&amp;rsquo;s handled by kubelet, which is can be seen in the kubelet configuration, there&amp;rsquo;s a section to specify in which the configuration must be used (resolvConf). By default, it&amp;rsquo;s &lt;code>/run/systemd/resolve/resolv.conf&lt;/code>&lt;/li>
&lt;li>Change the order of &lt;code>/run/systemd/resolve/resolv.conf&lt;/code>, so that &lt;code>nameserver 192.168.104.2&lt;/code> is on the top. Then recraate the pod&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="cni-plugin-in-worker-node-fail">CNI plugin in worker node fail&lt;/h1>
&lt;p>When I setup the worker node, the cni plugin fails. In the log, I see that the kubernetes IP is unreachable from worker node. When 10.96.0.1 in unreachable, we need know in which layer the network is unreachable.&lt;/p>
&lt;ul>
&lt;li>Use curl first, if it&amp;rsquo;s unreachable, then go down to the lower level&lt;/li>
&lt;li>In networking layer, we can use &lt;code>netcat&lt;/code> , use &lt;code>ip addr&lt;/code>, &lt;code>ip route&lt;/code> to know where the ip should be routed, if it&amp;rsquo;s still unreachable check using &lt;code>iptables&lt;/code> , in my case, the problem shown when I see &lt;code>iptables&lt;/code>:
&lt;ul>
&lt;li>the &lt;code>nat&lt;/code> table somehow configured to the wrong IP. eventho the IP is belong to the correct node that contains controlplane, but this IP is unreachable from worker node.&lt;/li>
&lt;li>I realized that my setting is 1 node with 2 interfaces at begining (when I bootstrap the cluster).
&lt;pre>&lt;code>controlplane
eth0 192.168.104.1/24
lima1 192.168.106.12/24
worker
eth0 192.168.104.8/24
lima1 192.168.106.15/24
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>lima1 interface is an interface that connect the node to my local. I use vzNAT. And through this interface, the IP between node is unreachable&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Root cause:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>The iptables that I have in worker node translate the destination of &lt;code>10.96.0.1&lt;/code> to &lt;code>192.168.106.12&lt;/code> that&amp;rsquo;s why it&amp;rsquo;s always fail to connect to api-server in controlplane&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Long term fix:
&lt;ul>
&lt;li>Hypothetically when bootstrap the kubernetes node, we need to pass the advertise ip for controlplane that can be reached by other nodes. In my case, I bootstrap the cluster without advertise ip&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Quick fix:
&lt;ul>
&lt;li>Route the ip &lt;code>192.168.106.12&lt;/code> directly to &lt;code>192.168.104.1&lt;/code> through eth0&lt;/li>
&lt;li>&lt;code>ip route add 192.168.106.12 via 192.168.104.1 dev eth0&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="coredns-in-worker-node-crashed">CoreDNS in worker node crashed&lt;/h1>
&lt;p>Truns out the ip forward is not enabled in worker node.&lt;/p>
&lt;p>&lt;strong>Fix:&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e"># sysctl params required by setup, params persist across reboots&lt;/span>
cat &lt;span style="color:#e6db74">&amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
&lt;/span>&lt;span style="color:#e6db74">net.ipv4.ip_forward = 1
&lt;/span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;span style="color:#75715e"># Apply sysctl params without reboot&lt;/span>
sudo sysctl --system
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h1 id="in-summary--references">In summary &amp;amp; references&lt;/h1>
&lt;p>There will be many networking issue comes. Knowing how networking works really save me. There&amp;rsquo;re some book that I found helpful during my debugging process:&lt;/p>
&lt;ul>
&lt;li>Networking for Systems Administrators - Michael Lucas&lt;/li>
&lt;li>Linux iptables Pocket Reference - Gregor N. Purdy&lt;/li>
&lt;li>&lt;a href="https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model/">Understanding kubernetes networking model - Kevin Sookocheff&lt;/a>&lt;/li>
&lt;/ul></content></item></channel></rss>